{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb073053",
   "metadata": {},
   "source": [
    "# WGU Capstone Project - Machine Learning\n",
    "Blake Sutton - Student ID: 001109490\n",
    "\n",
    "### Running the Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da3ec41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d96c82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting bike to the data in the BikeData.csv file\n",
    "bike = pd.read_csv(\"prediction_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "974e8149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature (C)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Functioning Day</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rented Bike Count  Hour  Temperature (C)  Humidity (%)  Seasons  Holiday  \\\n",
       "0                254     0             -5.2            37        1        0   \n",
       "1                204     1             -5.5            38        1        0   \n",
       "2                173     2             -6.0            39        1        0   \n",
       "3                107     3             -6.2            40        1        0   \n",
       "4                 78     4             -6.0            36        1        0   \n",
       "\n",
       "   Functioning Day  Precipitation  Day  Month  Year  \n",
       "0                1              0    1     12  2017  \n",
       "1                1              0    1     12  2017  \n",
       "2                1              0    1     12  2017  \n",
       "3                1              0    1     12  2017  \n",
       "4                1              0    1     12  2017  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Giving glimpse into the structure of the data\n",
    "bike.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e44f1",
   "metadata": {},
   "source": [
    "### Ensuring that no missing data exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5c8e205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rented Bike Count    0\n",
       "Hour                 0\n",
       "Temperature (C)      0\n",
       "Humidity (%)         0\n",
       "Seasons              0\n",
       "Holiday              0\n",
       "Functioning Day      0\n",
       "Precipitation        0\n",
       "Day                  0\n",
       "Month                0\n",
       "Year                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike.isna().sum() # Returns 0 for all columns, meaning no missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54ba87e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rented Bike Count      int64\n",
       "Hour                   int64\n",
       "Temperature (C)      float64\n",
       "Humidity (%)           int64\n",
       "Seasons                int64\n",
       "Holiday                int64\n",
       "Functioning Day        int64\n",
       "Precipitation          int64\n",
       "Day                    int64\n",
       "Month                  int64\n",
       "Year                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0e6295a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature (C)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Functioning Day</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rented Bike Count  Hour  Temperature (C)  Humidity (%)  Seasons  Holiday  \\\n",
       "0                254     0             -5.2            37        1        0   \n",
       "1                204     1             -5.5            38        1        0   \n",
       "2                173     2             -6.0            39        1        0   \n",
       "3                107     3             -6.2            40        1        0   \n",
       "4                 78     4             -6.0            36        1        0   \n",
       "\n",
       "   Functioning Day  Precipitation  Day  Month  Year  \n",
       "0                1              0    1     12  2017  \n",
       "1                1              0    1     12  2017  \n",
       "2                1              0    1     12  2017  \n",
       "3                1              0    1     12  2017  \n",
       "4                1              0    1     12  2017  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afe50e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Creating function to evaluate predictions later on\n",
    "def eval_classification(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    Performs evaluation comparison on y_true labels vs. y_preds labels\n",
    "    on a regressor model.\n",
    "    \"\"\"\n",
    "    print(\"Regression metrics on the test set\")\n",
    "    print(f\"R^2: {r2_score(y_test, y_preds)}\")\n",
    "    print(f\"MAE: {mean_absolute_error(y_test, y_preds)}\")\n",
    "    print(f\"MSE: {mean_squared_error(y_test, y_preds)}\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3329f9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8713721562285525"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid = {\"n_estimators\": [10, 100, 200, 500, 1000, 1200],\n",
    "        \"max_depth\": [None, 5, 10, 20, 30],\n",
    "        \"max_features\": [\"auto\", \"sqrt\"],\n",
    "        \"min_samples_split\": [2, 4, 6],\n",
    "        \"min_samples_leaf\": [1, 2, 4]}\n",
    "\n",
    "# x = bike.drop(\"Rented Bike Count\", axis=1)\n",
    "# Split into X & y\n",
    "X = bike.drop([\"Rented Bike Count\"], axis=1)\n",
    "y = bike[\"Rented Bike Count\"]\n",
    "X.to_csv(\"beforepredictions.csv\", index=False)\n",
    "\n",
    "# Define different features and transformer pipeline - now unnecessary\n",
    "#categorical_features = [\"Date\", \"Seasons\", \"Holiday\", \"Functioning Day\", \"Precipitation\"]\n",
    "\"\"\"\n",
    "categorical_features = categorical_features = [\"Date\", \"Seasons\", \"Holiday\", \"Functioning Day\", \"Precipitation\"]\n",
    "\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                                  remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X\n",
    "\"\"\"\n",
    "#Splitting into training and test data\n",
    "#X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "#clf = RandomForestRegressor(n_jobs=1)\n",
    "# Creating the model\n",
    "\n",
    "\n",
    "# Optimizing the model with RandomizedSearchCV\n",
    "# Setup RandomizedSearchCV\n",
    "\"\"\"\n",
    "# rs_clf = RandomizedSearchCV(estimator=clf,\n",
    "                            param_distributions=grid,\n",
    "                            n_iter=30, # number of models to try\n",
    "                            cv=5,\n",
    "                            verbose=2)\n",
    "clf = RandomForestRegressor(n_estimators=200,\n",
    "                            n_jobs=1,\n",
    "                            min_samples_split=2,\n",
    "                            min_samples_leaf=1,\n",
    "                            max_features='auto',\n",
    "                            max_depth=30)\n",
    "\"\"\"\n",
    "# Fit the RandomizedSearchCV version of clf\n",
    "# rs_clf.fit(X_train, y_train);\n",
    "\n",
    "clf = RandomForestRegressor(random_state=40)\n",
    "\n",
    "# Fitting with training data, then scoring with test data\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a73e595d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 30}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53352bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression metrics on the test set\n",
      "R^2: 0.8889664620626547\n",
      "MAE: 129.60513135527194\n",
      "MSE: 44222.23196352896\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6n/r0mykfwn6tn5_cbb6h96dln00000gn/T/ipykernel_44582/1409665117.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Evaluate the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrs_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrs_y_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrs_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_preds' is not defined"
     ]
    }
   ],
   "source": [
    "# Make predictions with the best hyperparameters\n",
    "rs_y_preds = rs_clf.predict(X_test)\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "rs_metrics = evaluate_preds(y_test, rs_y_preds)\n",
    "rs_metrics = evaluate_preds(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "437341f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   2.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   4.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   5.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   4.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   3.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   5.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   6.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   6.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   4.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   4.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   4.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   1.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   1.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   1.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   1.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   1.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000; total time=   3.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000; total time=   3.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000; total time=   3.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000; total time=   3.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000; total time=   3.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   4.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   4.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   3.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   4.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   5.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   2.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   1.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   1.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   1.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   4.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   4.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   4.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   4.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   3.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   2.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   4.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   8.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   6.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   6.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   5.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   4.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   6.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   7.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   7.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   7.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   5.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   2.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   2.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   2.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000; total time=   4.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000; total time=   5.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000; total time=   5.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000; total time=   5.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000; total time=   5.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   6.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   6.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   5.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   5.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   5.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   2.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   3.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   3.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   3.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   4.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   4.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   4.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   4.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   4.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   4.4s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   2.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   2.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   5.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   4.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   4.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   4.8s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   4.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   5.6s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   5.6s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   5.6s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   5.6s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   5.6s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   2.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000; total time=   4.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000; total time=   4.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000; total time=   4.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000; total time=   4.4s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000; total time=   4.9s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   5.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   5.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   7.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   5.8s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   6.9s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   1.8s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   3.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   3.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   3.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   3.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   3.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   4.5s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   4.4s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   4.5s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   4.5s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   4.4s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = {\"n_estimators\": [500, 1000, 1200],\n",
    "        \"max_depth\": [10, 20, 30],\n",
    "        \"max_features\": [\"sqrt\"],\n",
    "        \"min_samples_split\": [6],\n",
    "        \"min_samples_leaf\": [1, 2, 4]}\n",
    "\n",
    "# Split into X & y\n",
    "X = bike.drop([\"Date\", \n",
    "               \"Rented Bike Count\", \n",
    "               \"Hour\", \n",
    "               \"Wind speed (m/s)\", \n",
    "               \"Visibility (10m)\", \n",
    "               \"Dew point temperature (C)\", \n",
    "               \"Solar Radiation (MJ/m2)\", \n",
    "               \"Seasons\", \n",
    "               \"Holiday\", \n",
    "               \"Functioning Day\"], \n",
    "              axis=1)\n",
    "y = bike[\"Rented Bike Count\"]\n",
    "\n",
    "# Define different features and transformer pipeline\n",
    "#categorical_features = [\"Date\", \"Seasons\", \"Holiday\", \"Functioning Day\", \"Precipitation\"]\n",
    "categorical_features = [\"Precipitation\", \"Cloudy\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                                  remainder=\"passthrough\")\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "clf = RandomForestRegressor(n_jobs=1)\n",
    "\n",
    "# Setup GridSearchCV\n",
    "gs_clf = GridSearchCV(estimator=clf, \n",
    "                      param_grid=grid,\n",
    "                      cv=5, \n",
    "                      verbose=2)\n",
    "\n",
    "# Fit the GridSearchCV version of clf\n",
    "gs_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36729c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 1200}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa79c851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression metrics on the test set\n",
      "R^2: 0.5153633726589182\n",
      "MAE: 310.0785690581145\n",
      "MSE: 206408.08668853805\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the best hyperparameters\n",
    "gs_y_preds = gs_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "gs_metrics = evaluate_preds(y_test, gs_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bff82a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5153633726589182"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "612b0ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5245597499020062"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = {\"n_estimators\": [500, 1000, 1200],\n",
    "        \"max_depth\": [10, 20, 30],\n",
    "        \"max_features\": [\"sqrt\"],\n",
    "        \"min_samples_split\": [6],\n",
    "        \"min_samples_leaf\": [1, 2, 4]}\n",
    "\n",
    "# Split into X & y\n",
    "X = bike.drop([\"Rented Bike Count\"], axis=1)\n",
    "y = bike[\"Rented Bike Count\"]\n",
    "\n",
    "# Define different features and transformer pipeline\n",
    "#categorical_features = [\"Date\", \"Seasons\", \"Holiday\", \"Functioning Day\", \"Precipitation\"]\n",
    "categorical_features = categorical_features = [\"Date\", \"Seasons\", \"Holiday\", \"Functioning Day\", \"Precipitation\", \"Cloudy\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                                  remainder=\"passthrough\")\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "clf = RandomForestRegressor(n_estimators=5000,\n",
    "                            max_depth=None,\n",
    "                            n_jobs=1,\n",
    "                            min_samples_leaf=25,\n",
    "                            min_samples_split=6\n",
    "                            )\n",
    "\"\"\"\n",
    "{'max_depth': 10,\n",
    " 'max_features': 'sqrt',\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 6,\n",
    " 'n_estimators': 1200}\n",
    "\"\"\"\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e2cc31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
